{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download available [River Segment Surface Area Dataset](https://mint.isi.edu/ethiopia/datasets/browse/da6b6d47-7672-4e6e-a455-7bbc7e7ceb99) data using MINT Data Catalog API\n",
    "\n",
    "This notebook allows the user to set spatial and temporal filters to download surface area csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites: python 3.6 or later\n",
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# for converting metadata into a GIS ready geojson\n",
    "import shapely\n",
    "import pandas\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set spatial and temporal filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Download dataset's resources based on temporal and spatial coverage\n",
    "\n",
    "# directory where data will be downloaded (change the directory path as needed.)\n",
    "out_dir = os.getcwd() + '/data_download/'\n",
    "\n",
    "\n",
    "# ----- WARNING -----------------------------------------------------------------------------\n",
    "# Currently, there is a limit to the number of records that the API will return at once. \n",
    "# By default it's 20, but it's possible to return up to 2000 records by specifying the \n",
    "# appropriate limit. However, the dataset contains ~9000 resources, \n",
    "# which is why it's important to provide additional filtering criteria like spatial \n",
    "# and temporal coverage\n",
    "# -------------------------------------------------------------------------------------------\n",
    "limit = 20\n",
    "\n",
    "\n",
    "# Specifying spatial coverage as a lat/lon bounding box:\n",
    "# Bounding box search parameter is a 4-element numeric array (in WGS84 coordinate system) [xmin, ymin, xmax, ymax]\n",
    "# As a reminder, x is longitude, y is latitude\n",
    "\n",
    "# For example, bounding box for Ethiopia+SNNPR+KAT (adm level 2) is\n",
    "# {\"xmax\": 38.062137603759766, \"xmin\": 37.3511962890625, \"ymax\": 7.4791812896728525, \"ymin\": 7.147633552551269}\n",
    "# We don't have to match those coordinates exactly as data catalog supports \"within\" and \"intersects\" geospatial queries\n",
    "\n",
    "bounding_box = [41.468759, 3.775651, 42.024722, 4.126743]\n",
    "\n",
    "# Specifying temporal coverage as start/end times in ISO8601 format. Supported operators are: \n",
    "# gt (greater than), \n",
    "# gte (greater than or equal)\n",
    "# lt (less than),\n",
    "# lte (less than or equal)\n",
    "#\n",
    "# For example, to specify temporal coverage for the entire 2018, we will write \n",
    "start_time = \"2018-01-01T00:00:00\"\n",
    "end_time = \"2018-12-31T23:59:59\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data\n",
    "- A csv for each river segment with the spatial and temporal range will be downloaded in the out_dir folder\n",
    "- A txt file (metadata.txt) is created that contains name of the river segment files and their corresponding bounding box. The file metadata.txt has 7 columns: filename, lon_min,lat_min,lon_max,lat_max,start_time,end_time\n",
    "- A GIS ready metadata.geojson file is created that contains the bounding boxes of the downloaded segment with filename as their attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resources: 20\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051115400-1923.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051115400-1879.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051115400-1843.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051115400-1779.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051115400-1731.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-32202.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-32158.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-32122.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-32084.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-32044.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31998.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31954.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31908.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31864.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31818.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31780.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31736.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31690.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31644.csv\n",
      "https://data.mint.isi.edu/files/River_Segment_Surface_Area_Dataset//data-1051038740-31604.csv\n"
     ]
    }
   ],
   "source": [
    "# This is a convenience method to handle api responses.\n",
    "def handle_api_response(response, print_response=True):\n",
    "    parsed_response = response.json()\n",
    "\n",
    "    if print_response:\n",
    "        pp.pprint(parsed_response)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return parsed_response\n",
    "    elif response.status_code == 400:\n",
    "        raise Exception(\"Bad request ^\")\n",
    "    elif response.status_code == 403:\n",
    "        msg = \"Please make sure your request headers include X-Api-Key and that you are using correct url\"\n",
    "        raise Exception(msg)\n",
    "    else:\n",
    "        msg = \"\"\"It seems our server encountered an error which it doesn't know how to handle yet. \n",
    "        This sometimes happens with unexpected input(s). In order to help us diagnose and resolve the issue, \n",
    "        please notify Dan Feldman (danf@usc.edu) of this error.\"\"\"\n",
    "    \n",
    "    return parsed_response\n",
    "\n",
    "\n",
    "# Data Catalog api endpoint url \n",
    "url = \"https://api.mint-data-catalog.org\" # (fixed. Do not change)\n",
    "\n",
    "# Get session token to use the API\n",
    "resp = requests.get(f\"{url}/get_session_token\").json()\n",
    "api_key = resp['X-Api-Key']\n",
    "\n",
    "request_headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'X-Api-Key': api_key\n",
    "}\n",
    "\n",
    "# Set dataset_id (fixed. Do not change.)\n",
    "dataset_id = 'da6b6d47-7672-4e6e-a455-7bbc7e7ceb99'\n",
    "\n",
    "search_query = {\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"spatial_coverage__within\": bounding_box,    \n",
    "    \"start_time__gte\": start_time,\n",
    "    \"end_time__lte\": end_time,\n",
    "    \"limit\": limit\n",
    "}\n",
    "\n",
    "response = handle_api_response(requests.post(url + '/datasets/dataset_resources',\n",
    "                                                headers=request_headers,\n",
    "                                                json=search_query),print_response=False)\n",
    "\n",
    "num_resources = len(response['resources'])\n",
    "print('Number of resources: ' + str(num_resources))\n",
    "\n",
    "\n",
    "if os.path.isdir(out_dir)==False:\n",
    "    os.mkdir(out_dir)\n",
    "fid = open(out_dir + 'metadata.txt','w')\n",
    "fid.write('filename,lon_min,lat_min,lon_max,lat_max,start_time,end_time\\n')\n",
    "for i in range(num_resources):\n",
    "    cur_url = response['resources'][i]['resource_data_url']\n",
    "    print(cur_url)\n",
    "    cur_name = cur_url.split('/')[-1]\n",
    "    \n",
    "    # writing metadata to metadata.txt\n",
    "    xmin = response['resources'][i]['resource_metadata']['spatial_coverage']['value']['xmin']\n",
    "    ymin = response['resources'][i]['resource_metadata']['spatial_coverage']['value']['ymin']\n",
    "    xmax = response['resources'][i]['resource_metadata']['spatial_coverage']['value']['xmax']\n",
    "    ymax = response['resources'][i]['resource_metadata']['spatial_coverage']['value']['ymax']\n",
    "    start_time = response['resources'][i]['resource_metadata']['temporal_coverage']['start_time']\n",
    "    end_time = response['resources'][i]['resource_metadata']['temporal_coverage']['end_time']\n",
    "    fid.write(cur_name + ',' + str(xmin) + ',' + str(ymin) + ',' + str(xmax) + ',' + str(ymax) + ',' + start_time + ',' + end_time + '\\n')\n",
    "    \n",
    "    # downloading river segment csv\n",
    "    os.system('wget -O ' + out_dir + cur_name + ' ' + cur_url)\n",
    "    \n",
    "    # adding metadata to metadata.shp\n",
    "    lat_point_list = [ymax,ymax,ymin,ymin,ymax]\n",
    "    lon_point_list = [xmin,xmax,xmax,xmin,xmin]\n",
    "    polygon_geom = shapely.geometry.Polygon(zip(lon_point_list, lat_point_list))\n",
    "    \n",
    "    if i==0:\n",
    "        pf = geopandas.GeoDataFrame(index=[i], crs=\"EPSG:4326\", geometry=[polygon_geom])\n",
    "        pf['filename'] = cur_name\n",
    "    else:\n",
    "        cf = geopandas.GeoDataFrame(index=[i], crs=\"EPSG:4326\", geometry=[polygon_geom])\n",
    "        cf['filename'] = cur_name\n",
    "        pf = pandas.concat([pf,cf])\n",
    "\n",
    "        \n",
    "    \n",
    "fid.close()\n",
    "pf.to_file(filename=out_dir + 'metadata.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
